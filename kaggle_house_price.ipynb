{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%` not found.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingRegressor,RandomForestRegressor,StackingRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import model_selection\n",
    "import xgboost as xgb\n",
    "from sklearn import linear_model\n",
    "from sklearn import svm\n",
    "import lightgbm as lgbm\n",
    "from sklearn import pipeline\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform as sp_randFloat\n",
    "from scipy.stats import randint as sp_randInt\n",
    "from scipy.stats import boxcox\n",
    "from scipy.special import inv_boxcox\n",
    "\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1460, 81) (1459, 80)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/train.csv\")\n",
    "df_test=pd.read_csv(\"../data/test.csv\")\n",
    "y_full_score = pd.read_csv('../full-score.csv')\n",
    "print(df.shape,df_test.shape)\n",
    "df = df[df.GrLivArea < 4500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replace NaN values and Model may assume them to be numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def replace_nan(features):\n",
    "    str_club = [\"MSSubClass\",\"OverallQual\",\"OverallCond\",\"YearBuilt\",\"YearRemodAdd\",\"GarageYrBlt\",\n",
    "           \"MoSold\",\"YrSold\"]\n",
    "    regress_cols = [\"LotFrontage\",\"LotArea\",\"MasVnrArea\",\"BsmtFinSF1\",\"BsmtFinSF2\",\n",
    "                        \"BsmtUnfSF\",\"TotalBsmtSF\",\"1stFlrSF\",\"2ndFlrSF\",\"LowQualFinSF\",\"GarageArea\",\"WoodDeckSF\",\n",
    "                        \"OpenPorchSF\",\"EnclosedPorch\",\"3SsnPorch\",\"ScreenPorch\",\"PoolArea\",\"MiscVal\"]\n",
    "    na_club = [\"Alley\",\"GarageType\",\"FireplaceQu\",\"GarageFinish\",\"GarageQual\",\"GarageCond\",\"PoolQC\",\n",
    "              \"Fence\",\"MiscFeature\"]\n",
    "\n",
    "#     for cols in features.columns:\n",
    "#         if cols in str_club:\n",
    "#             features[cols] = features[cols].astype(str)\n",
    "    # filling mean for continuos column\n",
    "    for cols in features.columns:\n",
    "        if cols in regress_cols:\n",
    "            features[cols] = features[cols].fillna(features[cols].mean())\n",
    "\n",
    "    # filling NA for these looking at data and description\n",
    "    for cols in features.columns:\n",
    "        if cols in na_club:\n",
    "            features[cols] = features[cols].fillna(\"NA\")\n",
    "\n",
    "    temp = (regress_cols+na_club)\n",
    "    # filling the most comman occuring value for the rest\n",
    "    for cols in features.columns:\n",
    "        if cols not in temp and features[cols].isna().sum() > 0:\n",
    "            features[cols] = features[cols].fillna(features[cols].value_counts().idxmax())\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relation_with_price_graph(df):\n",
    "    df=df.fillna(df.mean())\n",
    "    cols = np.array(df.columns[1:-1])\n",
    "    regress_cols = [\"LotFrontage\",\"LotArea\",\"MasVnrArea\",\"BsmtFinSF1\",\"BsmtFinSF2\",\n",
    "                    \"BsmtUnfSF\",\"TotalBsmtSF\",\"1stFlrSF\",\"2ndFlrSF\",\"LowQualFinSF\",\"GarageArea\",\"WoodDeckSF\",\n",
    "                    \"OpenPorchSF\",\"EnclosedPorch\",\"3SsnPorch\",\"ScreenPorch\",\"PoolArea\",\"MiscVal\"]\n",
    "    y=df.iloc[:,-1]\n",
    "    temp_df=df.iloc[:,1:]\n",
    "    for i in cols:\n",
    "        plt.figure(figsize=(4,2), dpi = 130)\n",
    "        if i not in regress_cols:\n",
    "            sns.catplot(x=i, y=\"SalePrice\", kind=\"box\",data=temp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_correlation_matrix(df):    \n",
    "    sns.set(style=\"white\")\n",
    "    regress_cols = [\"LotFrontage\",\"LotArea\",\"MasVnrArea\",\"BsmtFinSF1\",\"BsmtFinSF2\",\n",
    "                    \"BsmtUnfSF\",\"TotalBsmtSF\",\"1stFlrSF\",\"2ndFlrSF\",\"LowQualFinSF\",\"GarageArea\",\"WoodDeckSF\",\n",
    "                    \"OpenPorchSF\",\"EnclosedPorch\",\"3SsnPorch\",\"ScreenPorch\",\"PoolArea\",\"MiscVal\",\"SalePrice\"]\n",
    "    df_temp=df[regress_cols].copy()\n",
    "    \n",
    "    # Compute the correlation matrix\n",
    "    corr = df_temp.corr()\n",
    "\n",
    "    # Generate a mask for the upper triangle\n",
    "    mask = np.triu(np.ones_like(corr, dtype=np.bool))\n",
    "\n",
    "    # Set up the matplotlib figure\n",
    "    f, ax = plt.subplots(figsize=(20, 10))\n",
    "\n",
    "    # Generate a custom diverging colormap\n",
    "    cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "\n",
    "    # Draw the heatmap with the mask and correct aspect ratio\n",
    "    sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n",
    "                square=True, linewidths=.5, cbar_kws={\"shrink\": .5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(X,test=False):\n",
    "    regress_cols = [\"LotFrontage\",\"LotArea\",\"MasVnrArea\",\"BsmtFinSF1\",\"BsmtFinSF2\",\n",
    "                    \"BsmtUnfSF\",\"TotalBsmtSF\",\"1stFlrSF\",\"2ndFlrSF\",\"LowQualFinSF\",\"GarageArea\",\"WoodDeckSF\",\n",
    "                    \"OpenPorchSF\",\"EnclosedPorch\",\"3SsnPorch\",\"ScreenPorch\",\"PoolArea\",\"MiscVal\",\"SalePrice\",\n",
    "                   \"GrLivArea\"]\n",
    "#     regress_cols = [\"Id\",\"LotFrontage\",\"LotArea\",\"YearBuilt\",\"YearRemodAdd\",\"MasVnrArea\",\"BsmtFinSF1\",\"BsmtFinSF2\",\n",
    "#                 \"BsmtUnfSF\",\"TotalBsmtSF\",\"1stFlrSF\",\"2ndFlrSF\",\"LowQualFinSF\",\"GarageYrBlt\",\"GarageArea\",\"WoodDeckSF\",\n",
    "#                 \"OpenPorchSF\",\"EnclosedPorch\",\"3SsnPorch\",\"ScreenPorch\",\"PoolArea\",\"MiscVal\",\"YrSold\",\"SalePrice\"]\n",
    "#     drop_cols = [\"BsmtFinSF2\",\"LowQualFinSF\",\"MiscVal\",\"3SsnPorch\"]\n",
    "#     X=X.drop(drop_cols,axis=1)\n",
    "#     X = X.drop(X['Id'])\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    for cols in X:\n",
    "        if (cols not in regress_cols):\n",
    "            X[cols] = le.fit_transform(X[cols].astype(str))\n",
    "#     X=X.fillna(X.mean())\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data before cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = replace_nan(df)\n",
    "df_test = replace_nan(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relation_with_price_graph(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "get_correlation_matrix(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Dummy variables: They suck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummy_vars(X):    \n",
    "    linear_cols = [\"Id\",\"LotFrontage\",\"LotArea\",\"MasVnrArea\",\"BsmtFinSF1\",\"BsmtFinSF2\",\n",
    "                            \"BsmtUnfSF\",\"TotalBsmtSF\",\"1stFlrSF\",\"2ndFlrSF\",\"LowQualFinSF\",\"GarageArea\",\"WoodDeckSF\",\n",
    "                            \"OpenPorchSF\",\"EnclosedPorch\",\"3SsnPorch\",\"ScreenPorch\",\"PoolArea\",\"MiscVal\",\n",
    "                   \"YearBuilt\",\"YearRemodAdd\",\"GarageYrBlt\",\"MoSold\",\"YrSold\",\"SalePrice\",\"GrLivArea\"]\n",
    "    temp = [x for x in X.columns if x not in linear_cols]\n",
    "    X = pd.get_dummies(X,columns=temp).reset_index(drop=True)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_df(df,df_test):\n",
    "    y = df['SalePrice']\n",
    "    train_features = df.drop(['SalePrice'], axis=1)\n",
    "    test_features = df_test\n",
    "    features = pd.concat([train_features, test_features]).reset_index(drop=True)\n",
    "    features = features.drop(['Id'],axis=1)\n",
    "\n",
    "    features = replace_nan(features)\n",
    "    features = preprocess_data(features)\n",
    "    # features = dummy_vars(features)\n",
    "    X = features.iloc[:len(y), :]\n",
    "    X_test = features.iloc[len(y):, :]\n",
    "    return (X,y,X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_file(model,test_data,lambda_):\n",
    "    y = model.predict(test_data)\n",
    "    y = inv_boxcox(y,lambda_)\n",
    "    ans=pd.DataFrame(y)\n",
    "    ans.index = np.arange(1461, len(ans)+1461)\n",
    "    ans.to_csv('output.csv',header=[\"SalePrice\"],index_label=[\"Id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning Paramerters of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_parameters_gbr(model,X,y,test_data,y_full_score,lambda_):\n",
    "    parameters = {'learning_rate': sp_randFloat(),\n",
    "                  'n_estimators' : sp_randInt(100, 2000),\n",
    "                  'max_depth' : sp_randInt(2, 12),\n",
    "                  'subsample': sp_randFloat()\n",
    "                 }\n",
    "    \n",
    "    randm = RandomizedSearchCV(estimator=model, param_distributions = parameters, \n",
    "                               cv = 5, n_iter = 10, n_jobs=-1)\n",
    "    randm.fit(X, y)\n",
    "    err(randm,test_data,y_full_score,lambda_)\n",
    "    return randm\n",
    "\n",
    "def tune_parameters_lgbr(model,X,y,test_data,y_full_score,lambda_):\n",
    "    parameters = {'learning_rate': sp_randFloat(),\n",
    "                  'n_estimators' : sp_randInt(100, 5000),\n",
    "                  'max_bin' : sp_randInt(100, 300),\n",
    "                  'num_leaves' : sp_randInt(2, 30),\n",
    "                  'bagging_fraction': sp_randFloat(),\n",
    "                  'subsample'    : sp_randFloat(),\n",
    "                  'colsample_bytree': sp_randFloat()\n",
    "                 }\n",
    "    \n",
    "    randm = RandomizedSearchCV(estimator=model, param_distributions = parameters, \n",
    "                               cv = 5, n_iter = 100, n_jobs=-1)\n",
    "    randm.fit(X, y)\n",
    "    err(randm,test_data,y_full_score,lambda_)\n",
    "    return randm\n",
    "\n",
    "def tune_parameters_xgb(model,X,y,test_data,y_full_score,lambda_):\n",
    "    parameters = {'learning_rate': sp_randFloat(),\n",
    "                  'n_estimators' : sp_randInt(100, 5000),\n",
    "                  'max_depth' : sp_randInt(2, 12),\n",
    "                  'subsample': sp_randFloat(),\n",
    "                  'colsample_bytree': sp_randFloat()\n",
    "                 }\n",
    "    \n",
    "    randm = RandomizedSearchCV(estimator=model, param_distributions = parameters, \n",
    "                               cv = 5, n_iter = 100, n_jobs=-1)\n",
    "    randm.fit(X, y)\n",
    "    err(randm,test_data,y_full_score,lambda_)\n",
    "    return randm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error with the Real result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "def err(model,test_data,y_full_score,lambda_):\n",
    "    y = model.predict(test_data)\n",
    "#     y[np.where(y<=0)] = 1\n",
    "    y_final = np.array(y_full_score.iloc[:,-1])\n",
    "    y = inv_boxcox(y,lambda_)\n",
    "    temp=(np.log(y)-np.log(y_final))\n",
    "    temp=np.sqrt(np.mean(temp**2))\n",
    "    print(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimized model before droping Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_optimized_models():\n",
    "    gbr = GradientBoostingRegressor(\n",
    "        learning_rate= 0.04822281322390631,\n",
    "        max_depth= 4,\n",
    "        n_estimators= 1784,\n",
    "        subsample= 0.672836260394989\n",
    "    )\n",
    "    \n",
    "    lgbr = lgbm.LGBMRegressor(\n",
    "        bagging_fraction= 0.24259298294498244,\n",
    "        colsample_bytree= 0.10555358953643856,\n",
    "        learning_rate= 0.02019821484348372,\n",
    "        max_bin= 242,\n",
    "        n_estimators= 7018,\n",
    "        num_leaves= 6,\n",
    "        subsample= 0.1345545567884744\n",
    "    )\n",
    "    xgbr = xgb.XGBRegressor(\n",
    "        colsample_bytree= 0.47024425419361326,\n",
    "        learning_rate= 0.02240271545343664,\n",
    "        max_depth= 4,\n",
    "        n_estimators= 2170,\n",
    "        subsample= 0.8283716383359659\n",
    "    )\n",
    "    return gbr,lgbr,xgbr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## optimized models after droping columns and fixing skew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_optimized_models_skew():\n",
    "    gbr = GradientBoostingRegressor(\n",
    "        learning_rate= 0.028418669171278887,\n",
    "        max_depth= 7,\n",
    "        n_estimators= 1407,\n",
    "        subsample= 0.36659208944052435\n",
    "    )\n",
    "    \n",
    "    lgbr = lgbm.LGBMRegressor(\n",
    "        bagging_fraction= 0.7596323409518068,\n",
    "        colsample_bytree= 0.2895341969083036,\n",
    "        learning_rate= 0.026228791957937814,\n",
    "        max_bin= 230,\n",
    "        n_estimators= 1517,\n",
    "        num_leaves= 13,\n",
    "        subsample= 0.7519907337203593\n",
    "    )\n",
    "    xgbr = xgb.XGBRegressor(\n",
    "        colsample_bytree= 0.11300308215161059,\n",
    "        learning_rate= 0.017276460305797103,\n",
    "        max_depth= 3,\n",
    "        n_estimators= 4318,\n",
    "        subsample= 0.8245317104774829\n",
    "    )\n",
    "    \n",
    "    KRR = KernelRidge(kernel='polynomial',coef0=2.5,alpha = 0.45200876633573595, degree = 1)\n",
    "    \n",
    "    ENet = make_pipeline(RobustScaler(), ElasticNet(\n",
    "    alpha= 0.0027644272078725107, \n",
    "    l1_ratio= 0.6305717058417957,\n",
    "    random_state= 15))\n",
    "    \n",
    "    lasso = make_pipeline(RobustScaler(), Lasso(\n",
    "    alpha= 0.0049556384660235375,\n",
    "    random_state= 23))\n",
    "    \n",
    "    return gbr,lgbr,xgbr,lasso,ENet,KRR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1458, 79) (1458,) (1459, 79) (1458,) -0.07712951475421644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shad3/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "X,y,test_data=get_df(df,df_test)\n",
    "y_box, lambda_ = boxcox(y)\n",
    "print(X.shape,y.shape,test_data.shape,y_box.shape,lambda_)\n",
    "gbr, lgbr,xgbr = create_optimized_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Without droping columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3937913328966712\n",
      "0.3914424822660915\n",
      "0.45610610412475505\n"
     ]
    }
   ],
   "source": [
    "for i in [gbr, lgbr,xgbr]:\n",
    "    i.fit(X,y_box)\n",
    "    err(i,test_data,y_full_score,lambda_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## here we drop column in pre-process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_train=pd.read_csv(\"../data/train.csv\")\n",
    "df_test=pd.read_csv(\"../data/test.csv\")\n",
    "df_train = df_train[df_train.GrLivArea < 4500]\n",
    "\n",
    "total = df_train.isnull().sum().sort_values(ascending=False)\n",
    "percent = (df_train.isnull().sum()/df_train.isnull().count()).sort_values(ascending=False)\n",
    "missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
    "# print(missing_data.head(20))\n",
    "\n",
    "df_train = df_train.drop((missing_data[missing_data['Total'] > 1]).index,1)\n",
    "df_test = df_test.drop((missing_data[missing_data['Total'] > 1]).index,1)\n",
    "df_train = df_train.drop(df_train.loc[df_train['Electrical'].isnull()].index)\n",
    "\n",
    "# df_train = preprocess_data(df_train)\n",
    "# df_test = preprocess_data(df_test)\n",
    "\n",
    "y_n = df_train['SalePrice']\n",
    "test_data = df_test.drop(['Id'],axis=1)\n",
    "df_train = df_train.drop(['Id','SalePrice'],axis=1)\n",
    "test_data = replace_nan(test_data)\n",
    "\n",
    "features = pd.concat([df_train, test_data]).reset_index(drop=True)\n",
    "features = dummy_vars(features)\n",
    "\n",
    "X_n = features.iloc[:len(y_n), :]\n",
    "test_data = features.iloc[len(y_n):, :]\n",
    "\n",
    "# test_data = dummy_vars(test_data)\n",
    "# df_train = dummy_vars(df_train)\n",
    "y_n_box, lambda_ = boxcox(y_n)\n",
    "gbr_new, lgbr_new,xgbr_new = create_optimized_models_skew()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## After droping columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13799633226841798\n",
      "0.13142629126165878\n",
      "0.1312013247062314\n"
     ]
    }
   ],
   "source": [
    "# y_n = df_train['SalePrice']\n",
    "# # X_n = df_train.drop(['Id','SalePrice'],axis=1)\n",
    "# y_n_box, lambda_ = boxcox(y_n)\n",
    "for i in [gbr_new,lgbr_new,xgbr_new]:\n",
    "    i.fit(X_n,y_n_box)\n",
    "    err(i,test_data,y_full_score,lambda_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13741793193822807\n",
      "\n",
      " The best parameters across ALL searched params:\n",
      " {'colsample_bytree': 0.8794988040295653, 'learning_rate': 0.4479943613065446, 'max_depth': 2, 'n_estimators': 7131, 'subsample': 0.9877609228494757}\n"
     ]
    }
   ],
   "source": [
    "regressor = xgb.XGBRegressor()\n",
    "xgb_dummy = tune_parameters_xgb(regressor,X_n,y_n_box,test_data,y_full_score,lambda_)\n",
    "print(\"\\n The best parameters across ALL searched params:\\n\",\n",
    "          xgb_dummy.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1309787221468581\n",
      "\n",
      " The best parameters across ALL searched params:\n",
      " {'colsample_bytree': 0.8794988040295653, 'learning_rate': 0.4479943613065446, 'max_depth': 2, 'n_estimators': 7131, 'subsample': 0.9877609228494757}\n"
     ]
    }
   ],
   "source": [
    "regressor = lgbm.LGBMRegressor(objective='regression')\n",
    "lgbm_dummy = tune_parameters_lgbr(regressor,X_n,y_n_box,test_data,y_full_score,lambda_)\n",
    "print(\"\\n The best parameters across ALL searched params:\\n\",\n",
    "          lgbm_dummy.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16413726935597472\n",
      "\n",
      " The best parameters across ALL searched params:\n",
      " {'learning_rate': 0.21165708825976437, 'max_depth': 7, 'n_estimators': 540, 'subsample': 0.39210125553893194}\n"
     ]
    }
   ],
   "source": [
    "regressor = GradientBoostingRegressor()\n",
    "gbr_dummy = tune_parameters_gbr(regressor,X_n,y_n_box,test_data,y_full_score,lambda_)\n",
    "print(\"\\n The best parameters across ALL searched params:\\n\",\n",
    "          gbr_dummy.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.linear_model import ElasticNet, Lasso,  BayesianRidge, LassoLarsIC\n",
    "from sklearn.kernel_ridge import KernelRidge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_lasso(model,X,y,test_data,y_full_score,lambda_):\n",
    "    parameters = {'lasso__alpha': sp_randFloat(),\n",
    "                  'lasso__random_state' : sp_randInt(1, 100)\n",
    "                 }\n",
    "    \n",
    "    randm = RandomizedSearchCV(estimator=model, param_distributions = parameters, \n",
    "                               cv = 5, n_iter = 100, n_jobs=-1)\n",
    "    randm.fit(X, y)\n",
    "    err(randm,test_data,y_full_score,lambda_)\n",
    "    return randm\n",
    "\n",
    "def tune_enet(model,X,y,test_data,y_full_score,lambda_):\n",
    "    parameters = {'elasticnet__alpha': sp_randFloat(),\n",
    "                  'elasticnet__l1_ratio': sp_randFloat(),\n",
    "                  'elasticnet__random_state' : sp_randInt(1, 100)\n",
    "                 }\n",
    "    \n",
    "    randm = RandomizedSearchCV(estimator=model, param_distributions = parameters, \n",
    "                               cv = 5, n_iter = 100, n_jobs=-1)\n",
    "    randm.fit(X, y)\n",
    "    err(randm,test_data,y_full_score,lambda_)\n",
    "    return randm\n",
    "\n",
    "def tune_krr(model,X,y,test_data,y_full_score,lambda_):\n",
    "    parameters = {'alpha': sp_randFloat(),\n",
    "                  'degree' : sp_randInt(1, 100)\n",
    "                 }\n",
    "    \n",
    "    randm = RandomizedSearchCV(estimator=model, param_distributions = parameters, \n",
    "                               cv = 5, n_iter = 100, n_jobs=-1)\n",
    "    randm.fit(X, y)\n",
    "    err(randm,test_data,y_full_score,lambda_)\n",
    "    return randm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = make_pipeline(RobustScaler(), Lasso())\n",
    "ENet = make_pipeline(RobustScaler(), ElasticNet())\n",
    "KRR = KernelRidge(kernel='polynomial',coef0=2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1849039793883354\n",
      "\n",
      " The best parameters across ALL searched params:\n",
      " {'lasso__alpha': 0.0049556384660235375, 'lasso__random_state': 23}\n"
     ]
    }
   ],
   "source": [
    "lasso_tuned = tune_lasso(lasso,X_n,y_n_box,test_data,y_full_score,lambda_)\n",
    "print(\"\\n The best parameters across ALL searched params:\\n\",\n",
    "          lasso_tuned.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15653674014026692\n",
      "\n",
      " The best parameters across ALL searched params:\n",
      " {'alpha': 0.45200876633573595, 'degree': 1}\n"
     ]
    }
   ],
   "source": [
    "krr_tuned = tune_krr(KRR,X_n,y_n_box,test_data,y_full_score,lambda_)\n",
    "print(\"\\n The best parameters across ALL searched params:\\n\",\n",
    "          krr_tuned.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1694584481752954\n",
      "\n",
      " The best parameters across ALL searched params:\n",
      " {'elasticnet__alpha': 0.0027644272078725107, 'elasticnet__l1_ratio': 0.6305717058417957, 'elasticnet__random_state': 15}\n"
     ]
    }
   ],
   "source": [
    "enet_tuned = tune_enet(ENet,X_n,y_n_box,test_data,y_full_score,lambda_)\n",
    "print(\"\\n The best parameters across ALL searched params:\\n\",\n",
    "          enet_tuned.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr_final, lgbr_final, xgbr_final, lasso_final, enet_final, krr_final = create_optimized_models_skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [gbr_final, lgbr_final, xgbr_final, lasso_final, enet_final, krr_final]:\n",
    "    i.fit(X_n,y_n_box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [],
   "source": [
    "vr = ensemble.VotingRegressor([('gb', gbr_final), ('xgbr', krr_final)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pred = (\n",
    "    0.4*lgbr_final.predict(test_data)+\n",
    "    0.3*xgbr_final.predict(test_data)+\n",
    "    0.3*gbr_final.predict(test_data)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1402497984251759\n"
     ]
    }
   ],
   "source": [
    "final_pred = vr.predict(test_data)\n",
    "y_final = np.array(y_full_score.iloc[:,-1])\n",
    "final_pred = inv_boxcox(final_pred,lambda_)\n",
    "temp=(np.log(final_pred)-np.log(y_final))\n",
    "temp=np.sqrt(np.mean(temp**2))\n",
    "print(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingRegressor(estimators=[('gb',\n",
       "                             GradientBoostingRegressor(learning_rate=0.028418669171278887,\n",
       "                                                       max_depth=7,\n",
       "                                                       n_estimators=1407,\n",
       "                                                       subsample=0.36659208944052435)),\n",
       "                            ('xgbr',\n",
       "                             KernelRidge(alpha=0.45200876633573595, coef0=2.5,\n",
       "                                         degree=1, kernel='polynomial'))])"
      ]
     },
     "execution_count": 488,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vr.fit(X_n,y_n_box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
